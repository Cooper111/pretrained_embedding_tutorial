{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在这个内核中，我想说明在构建深度学习NLP模型时如何进行有意义的预处理。\n",
    "#我开始的两条黄金法则:\n",
    "#1.使用标准的预处理步骤不喜欢阻止或stopword切除时pre-trained嵌入\n",
    "#一些您可能使用标准的预处理步骤时基于字数等特征提取(例如TFIDF)删除stopwords,引发等。原因很简单:你宽松的有价值的信息,这将有助于你神经网络图的东西。\n",
    "#2.让你的词汇量尽可能接近嵌入\n",
    "#我将集中在这个笔记本，如何实现这一点。以GoogleNews预培训的嵌入式为例，这种选择没有更深层次的原因。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1306122, 3)\n",
      "Test shape: (56370, 2)\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "print('Train shape:', train.shape)\n",
    "print('Test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#我将使用下面的函数来跟踪我们的训练词汇，它将遍历我们的所有文本并计算包含的单词的出现次数。\n",
    "def build_vocab(sentences, verbose = True):\n",
    "    # 参数  sentences list of list of words，就是二维的\n",
    "    # 返回值 对应  词和词的次数 的字典\n",
    "    vocab = {}\n",
    "    for sentence in tqdm(sentences, disable = (not verbose)):\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 1306122/1306122 [00:04<00:00, 266825.76it/s]\n",
      "100%|███| 1306122/1306122 [00:05<00:00, 254818.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'How': 261930, 'did': 33489, 'Quebec': 97, 'nationalists': 91, 'see': 9003}\n"
     ]
    }
   ],
   "source": [
    "#因此，让我们填充词汇表并显示前5个元素及其计数。注意，现在我们可以使用progess_apply查看进度条\n",
    "sentences = train['question_text'].progress_apply(lambda x: x.split()).values\n",
    "vocab = build_vocab(sentences)\n",
    "print({k: vocab[k] for k in list(vocab)[:5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#接下来，我们导入我们稍后要在模型中使用的Embedding。为了说明这一点，我在这里使用GoogleNews\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "news_path = '../input/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
    "embedding_index = KeyedVectors.load_word2vec_format(news_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#接下来，我定义一个函数来检查词汇表和嵌入之间的交集。它将输出一个out of vocabulary (oov)单词列表，我们可以使用它来改进我们的预处理\n",
    "import operator\n",
    "def check_coverage(vocab, embeddings_index):\n",
    "    a = {}\n",
    "    oov = {}\n",
    "    k = 0\n",
    "    i = 0\n",
    "    for word in tqdm(vocab):\n",
    "        try:\n",
    "            a[word] = embeddings_index[word]\n",
    "            k += vocab[word]\n",
    "        except:\n",
    "            oov[word] = vocab[word]\n",
    "            i += vocab[word]\n",
    "            pass\n",
    "    \n",
    "    print('Found embeddings for {:.2%} of vocab'.format(len(a) /  len(vocab)))\n",
    "    print('Found embeddings for {:.2%} of all text'.format(k / (k + i)))\n",
    "    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]#取axis=1维度进行排序，并换为逆序\n",
    "    \n",
    "    return sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████| 508823/508823 [00:01<00:00, 374703.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 24.31% of vocab\n",
      "Found embeddings for 78.75% of all text\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab, embedding_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 403183),\n",
       " ('a', 402682),\n",
       " ('of', 330825),\n",
       " ('and', 251973),\n",
       " ('India?', 16384),\n",
       " ('it?', 12900),\n",
       " ('do?', 8753),\n",
       " ('life?', 7753),\n",
       " ('you?', 6295),\n",
       " ('me?', 6202)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#哎哟，只有24%的词汇表会有嵌入，这使得21%的数据或多或少是无用的。所以让我们来看看并开始改进。为此，我们可以很容易地看一看顶部的oov单词\n",
    "oov[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#：首先是“to”。为什么?仅仅是因为“to”在训练GoogleNews嵌入时被删除了。稍后我们将对此进行修复，因为现在我们要注意标点符号的分割，因为这似乎也是一个问题。但是，我们该如何处理标点符号呢?我们是想删除标点符号，还是将其视为一种标记?我想说:这要看情况。如果标记有嵌入，保留它，如果没有，我们就不再需要它了。我们检查:\n",
    "print('?' in embedding_index)\n",
    "print('&' in embedding_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#有趣。虽然“&”出现在谷歌新闻的嵌入中，“?”却不是。因此，我们基本上定义了一个函数，它分割“&”并删除其他标点符号。\n",
    "\n",
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in \"/-'\":\n",
    "        x = x.replace(punct, ' ')\n",
    "    for punct in '&':\n",
    "        x = x.replace(punct, f' {punct} ')#f''解释：你不再需要直接调用一个字符串的.format()方法，但是要简单地用前缀f来标记格式以及内联最终字符串中你想要包括的表达式，不然它们就会被期望着去提供如同你从.format()函数得到的相同功能。这些格式化字符串也在文档中被称为“f字符串”。\n",
    "    for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~' + '“”’':\n",
    "        x = x.replace(punct, '')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████| 1306122/1306122 [00:16<00:00, 79190.25it/s]\n",
      "100%|███| 1306122/1306122 [00:05<00:00, 218846.61it/s]\n"
     ]
    }
   ],
   "source": [
    "train['question_text'] =  train['question_text'].progress_apply(lambda x: clean_text(x))\n",
    "sentences = train['question_text'].apply(lambda x: x.split())\n",
    "vocab = build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████| 253623/253623 [00:00<00:00, 329145.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 57.38% of vocab\n",
      "Found embeddings for 89.99% of all text\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab, embedding_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 406298),\n",
       " ('a', 403852),\n",
       " ('of', 332964),\n",
       " ('and', 254081),\n",
       " ('2017', 8781),\n",
       " ('2018', 7373),\n",
       " ('10', 6642),\n",
       " ('12', 3694),\n",
       " ('20', 2942),\n",
       " ('100', 2883)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#好了!我们能够增加我们的嵌入比从24%到57%仅仅通过处理穿刺。好的，让我们检查一下这些单词。\n",
    "oov[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KeyedVectors' object has no attribute 'index2entity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-7aac54b0cb07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#嗯，似乎数字也是个问题。让我们检查一下前10个嵌入来获得线索。\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex2entity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyedVectors' object has no attribute 'index2entity'"
     ]
    }
   ],
   "source": [
    "#嗯，似乎数字也是个问题。让我们检查一下前10个嵌入来获得线索。\n",
    "for i in range(10):\n",
    "    print(embedding_index.index2entity[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#为什么里面有\"##\" ?原因很简单，因为作为一个再处理，所有大于9的数字都被hashs替换了。即成为# #,123变成# # #或15.80€变成# #,# #€。因此，让我们模拟这个预处理步骤来进一步改进我们的嵌入式覆盖率\n",
    "import re\n",
    "\n",
    "def clean_numbers(x):\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████| 1306122/1306122 [00:16<00:00, 80227.57it/s]\n",
      "100%|███| 1306122/1306122 [00:05<00:00, 249280.32it/s]\n",
      "100%|███| 1306122/1306122 [00:05<00:00, 259681.59it/s]\n"
     ]
    }
   ],
   "source": [
    "train['question_text'] = train['question_text'].progress_apply(lambda x: clean_numbers(x))\n",
    "sentences = train['question_text'].progress_apply(lambda x: x.split())\n",
    "vocab = build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████| 242997/242997 [00:00<00:00, 319105.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 60.41% of vocab\n",
      "Found embeddings for 90.75% of all text\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab,embedding_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 406298),\n",
       " ('a', 403852),\n",
       " ('of', 332964),\n",
       " ('and', 254081),\n",
       " ('2017', 8781),\n",
       " ('2018', 7373),\n",
       " ('10', 6642),\n",
       " ('12', 3694),\n",
       " ('20', 2942),\n",
       " ('100', 2883),\n",
       " ('15', 2762),\n",
       " ('12th', 2551),\n",
       " ('11', 2356),\n",
       " ('30', 2163),\n",
       " ('18', 2066),\n",
       " ('50', 1993),\n",
       " ('16', 1589),\n",
       " ('14', 1533),\n",
       " ('17', 1505),\n",
       " ('13', 1390)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#好了!另一个3%的增长。现在就像处理撞击一样，但是每一点都有帮助。让我们检查oov单词\n",
    "oov[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#好了，现在我们来处理一下在使用美式/英式vocab时常见的拼写错误，并将一些“现代”单词替换为“social media”。此外，我们将简单地删除“a”、“to”、“and”和“of”等词，因为在培训GoogleNews嵌入式时，这些词显然已被下采样。\n",
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))#编写一个正则式\n",
    "    return mispell_dict, mispell_re\n",
    "\n",
    "\n",
    "mispell_dict = {'colour':'color',\n",
    "                'centre':'center',\n",
    "                'didnt':'did not',\n",
    "                'doesnt':'does not',\n",
    "                'isnt':'is not',\n",
    "                'shouldnt':'should not',\n",
    "                'favourite':'favorite',\n",
    "                'travelling':'traveling',\n",
    "                'counselling':'counseling',\n",
    "                'theatre':'theater',\n",
    "                'cancelled':'canceled',\n",
    "                'labour':'labor',\n",
    "                'organisation':'organization',\n",
    "                'wwii':'world war 2',\n",
    "                'citicise':'criticize',\n",
    "                'instagram': 'social medium',\n",
    "                'whatsapp': 'social medium',\n",
    "                'snapchat': 'social medium'\n",
    "\n",
    "                }\n",
    "mispellings, mispellings_re = _get_mispell(mispell_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_typical_misspell(text):\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "\n",
    "    return mispellings_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                     | 0/1306122 [00:00<?, ?it/s]\n",
      "  1%|     | 11727/1306122 [00:00<00:11, 116416.34it/s]\n",
      "  2%|     | 30571/1306122 [00:00<00:09, 131288.09it/s]\n",
      "  4%|▏    | 49145/1306122 [00:00<00:08, 143715.22it/s]\n",
      "  5%|▎    | 68121/1306122 [00:00<00:08, 154721.00it/s]\n",
      "  7%|▎    | 87093/1306122 [00:00<00:07, 163476.85it/s]\n",
      "  8%|▎   | 105626/1306122 [00:00<00:07, 169118.02it/s]\n",
      " 10%|▍   | 124101/1306122 [00:00<00:06, 173166.11it/s]\n",
      " 11%|▍   | 143467/1306122 [00:00<00:06, 178484.38it/s]\n",
      " 12%|▍   | 163252/1306122 [00:00<00:06, 183508.04it/s]\n",
      " 14%|▌   | 181392/1306122 [00:01<00:06, 181354.71it/s]\n",
      " 15%|▌   | 199386/1306122 [00:01<00:06, 174507.78it/s]\n",
      " 17%|▋   | 216793/1306122 [00:01<00:06, 163104.15it/s]\n",
      " 18%|▋   | 234639/1306122 [00:01<00:06, 167386.47it/s]\n",
      " 19%|▊   | 254011/1306122 [00:01<00:06, 174388.73it/s]\n",
      " 21%|▊   | 273563/1306122 [00:01<00:05, 179869.00it/s]\n",
      " 22%|▉   | 291702/1306122 [00:01<00:05, 177298.68it/s]\n",
      " 24%|▉   | 311585/1306122 [00:01<00:05, 182867.13it/s]\n",
      " 25%|█   | 331034/1306122 [00:01<00:05, 185825.79it/s]\n",
      " 27%|█   | 350033/1306122 [00:01<00:05, 186660.03it/s]\n",
      " 28%|█▏  | 369543/1306122 [00:02<00:04, 188713.76it/s]\n",
      " 30%|█▏  | 389234/1306122 [00:02<00:04, 190676.99it/s]\n",
      " 31%|█▎  | 408965/1306122 [00:02<00:04, 192208.42it/s]\n",
      " 33%|█▎  | 428219/1306122 [00:02<00:04, 190366.21it/s]\n",
      " 34%|█▎  | 448524/1306122 [00:02<00:04, 193598.85it/s]\n",
      " 36%|█▍  | 468425/1306122 [00:02<00:04, 194771.21it/s]\n",
      " 37%|█▍  | 487927/1306122 [00:02<00:04, 193842.92it/s]\n",
      " 39%|█▌  | 507330/1306122 [00:02<00:04, 192497.96it/s]\n",
      " 40%|█▌  | 526595/1306122 [00:02<00:04, 180553.95it/s]\n",
      " 42%|█▋  | 544812/1306122 [00:02<00:04, 177735.67it/s]\n",
      " 43%|█▋  | 564557/1306122 [00:03<00:04, 182867.43it/s]\n",
      " 45%|█▊  | 583580/1306122 [00:03<00:03, 184620.78it/s]\n",
      " 46%|█▊  | 602133/1306122 [00:03<00:03, 182321.18it/s]\n",
      " 48%|█▉  | 620435/1306122 [00:03<00:03, 181590.79it/s]\n",
      " 49%|█▉  | 639600/1306122 [00:03<00:03, 184108.92it/s]\n",
      " 50%|██  | 659352/1306122 [00:03<00:03, 187544.12it/s]\n",
      " 52%|██  | 678401/1306122 [00:03<00:03, 188011.57it/s]\n",
      " 53%|██▏ | 697235/1306122 [00:03<00:03, 186829.94it/s]\n",
      " 55%|██▏ | 715943/1306122 [00:03<00:03, 182150.63it/s]\n",
      " 56%|██▏ | 734201/1306122 [00:04<00:03, 179195.96it/s]\n",
      " 58%|██▎ | 752162/1306122 [00:04<00:03, 178397.31it/s]\n",
      " 59%|██▎ | 772026/1306122 [00:04<00:02, 183901.93it/s]\n",
      " 61%|██▍ | 791545/1306122 [00:04<00:02, 186741.14it/s]\n",
      " 62%|██▍ | 811467/1306122 [00:04<00:02, 189932.76it/s]\n",
      " 64%|██▌ | 831070/1306122 [00:04<00:02, 191314.13it/s]\n",
      " 65%|██▌ | 850240/1306122 [00:04<00:02, 188186.96it/s]\n",
      " 67%|██▋ | 869098/1306122 [00:04<00:02, 184605.77it/s]\n",
      " 68%|██▋ | 888029/1306122 [00:04<00:02, 185596.66it/s]\n",
      " 69%|██▊ | 906620/1306122 [00:04<00:02, 183642.24it/s]\n",
      " 71%|██▊ | 925011/1306122 [00:05<00:02, 178529.28it/s]\n",
      " 72%|██▉ | 944306/1306122 [00:05<00:01, 182233.19it/s]\n",
      " 74%|██▉ | 963091/1306122 [00:05<00:01, 183501.89it/s]\n",
      " 75%|███ | 982721/1306122 [00:05<00:01, 186755.99it/s]\n",
      " 77%|██▎| 1001564/1306122 [00:05<00:01, 186865.01it/s]\n",
      " 78%|██▎| 1020280/1306122 [00:05<00:01, 177617.31it/s]\n",
      " 79%|██▍| 1038158/1306122 [00:05<00:01, 176425.81it/s]\n",
      " 81%|██▍| 1055884/1306122 [00:05<00:01, 174762.00it/s]\n",
      " 82%|██▍| 1075189/1306122 [00:05<00:01, 179724.63it/s]\n",
      " 84%|██▌| 1095021/1306122 [00:05<00:01, 184819.18it/s]\n",
      " 85%|██▌| 1114281/1306122 [00:06<00:01, 186688.45it/s]\n",
      " 87%|██▌| 1133019/1306122 [00:06<00:00, 185934.67it/s]\n",
      " 88%|██▋| 1151661/1306122 [00:06<00:00, 182411.78it/s]\n",
      " 90%|██▋| 1169952/1306122 [00:06<00:00, 181081.75it/s]\n",
      " 91%|██▋| 1188097/1306122 [00:06<00:00, 178666.83it/s]\n",
      " 92%|██▊| 1205997/1306122 [00:06<00:00, 176779.09it/s]\n",
      " 94%|██▊| 1224641/1306122 [00:06<00:00, 179208.16it/s]\n",
      " 95%|██▊| 1242674/1306122 [00:06<00:00, 179153.02it/s]\n",
      " 97%|██▉| 1261028/1306122 [00:06<00:00, 180058.52it/s]\n",
      " 98%|██▉| 1279049/1306122 [00:07<00:00, 175520.64it/s]\n",
      " 99%|██▉| 1297771/1306122 [00:07<00:00, 178485.67it/s]\n",
      "100%|███| 1306122/1306122 [00:07<00:00, 179723.74it/s]\n",
      "  0%|                     | 0/1306122 [00:00<?, ?it/s]\n",
      "  2%|     | 19770/1306122 [00:00<00:06, 196276.65it/s]\n",
      "  4%|▏    | 52114/1306122 [00:00<00:05, 222184.13it/s]\n",
      "  7%|▎    | 84949/1306122 [00:00<00:04, 245651.77it/s]\n",
      "  9%|▎   | 118742/1306122 [00:00<00:04, 267107.67it/s]\n",
      " 12%|▍   | 151915/1306122 [00:00<00:04, 283119.76it/s]\n",
      " 14%|▌   | 180806/1306122 [00:00<00:03, 284259.51it/s]\n",
      " 16%|▋   | 211236/1306122 [00:00<00:03, 289384.22it/s]\n",
      " 18%|▋   | 240005/1306122 [00:00<00:03, 288568.25it/s]\n",
      " 21%|▊   | 271492/1306122 [00:00<00:03, 295543.88it/s]\n",
      " 23%|▉   | 303744/1306122 [00:01<00:03, 302779.28it/s]\n",
      " 26%|█   | 340001/1306122 [00:01<00:03, 317799.71it/s]\n",
      " 28%|█▏  | 371814/1306122 [00:01<00:02, 314823.31it/s]\n",
      " 31%|█▏  | 403730/1306122 [00:01<00:02, 315887.08it/s]\n",
      " 34%|█▎  | 438336/1306122 [00:01<00:02, 323339.88it/s]\n",
      " 36%|█▍  | 473779/1306122 [00:01<00:02, 331883.32it/s]\n",
      " 39%|█▌  | 508572/1306122 [00:01<00:02, 335811.01it/s]\n",
      " 42%|█▋  | 542233/1306122 [00:01<00:02, 334326.05it/s]\n",
      " 44%|█▊  | 578425/1306122 [00:01<00:02, 341423.56it/s]\n",
      " 47%|█▉  | 614085/1306122 [00:01<00:02, 345139.39it/s]\n",
      " 50%|█▉  | 649810/1306122 [00:02<00:01, 347909.57it/s]\n",
      " 53%|██  | 686681/1306122 [00:02<00:01, 353150.70it/s]\n",
      " 55%|██▏ | 722486/1306122 [00:02<00:01, 353876.73it/s]\n",
      " 58%|██▎ | 757987/1306122 [00:02<00:01, 352354.75it/s]\n",
      " 61%|██▍ | 793251/1306122 [00:02<00:01, 350625.20it/s]\n",
      " 63%|██▌ | 828957/1306122 [00:02<00:01, 351737.15it/s]\n",
      " 66%|██▋ | 864147/1306122 [00:02<00:01, 351049.13it/s]\n",
      " 69%|██▊ | 899264/1306122 [00:02<00:01, 345133.67it/s]\n",
      " 72%|██▊ | 934728/1306122 [00:02<00:01, 347218.06it/s]\n",
      " 74%|██▉ | 969475/1306122 [00:02<00:01, 313765.19it/s]\n",
      " 77%|██▎| 1001955/1306122 [00:03<00:00, 316319.39it/s]\n",
      " 79%|██▍| 1037449/1306122 [00:03<00:00, 326335.61it/s]\n",
      " 82%|██▍| 1072289/1306122 [00:03<00:00, 331961.04it/s]\n",
      " 85%|██▌| 1108408/1306122 [00:03<00:00, 339518.49it/s]\n",
      " 88%|██▋| 1144206/1306122 [00:03<00:00, 344100.47it/s]\n",
      " 90%|██▋| 1179285/1306122 [00:03<00:00, 345329.94it/s]\n",
      " 93%|██▊| 1215513/1306122 [00:03<00:00, 349531.92it/s]\n",
      " 96%|██▊| 1251657/1306122 [00:03<00:00, 352232.09it/s]\n",
      " 99%|██▉| 1286960/1306122 [00:03<00:00, 351702.14it/s]\n",
      "100%|███| 1306122/1306122 [00:03<00:00, 330858.24it/s]\n",
      "  0%|                     | 0/1306122 [00:00<?, ?it/s]\n",
      "  2%|     | 31915/1306122 [00:00<00:04, 316844.02it/s]\n",
      "  5%|▎    | 67049/1306122 [00:00<00:03, 326350.31it/s]\n",
      "  8%|▎   | 102439/1306122 [00:00<00:03, 333927.07it/s]\n",
      " 10%|▍   | 134545/1306122 [00:00<00:03, 329216.61it/s]\n",
      " 13%|▌   | 170813/1306122 [00:00<00:03, 337869.40it/s]\n",
      " 16%|▋   | 204571/1306122 [00:00<00:03, 337044.50it/s]\n",
      " 18%|▋   | 234628/1306122 [00:00<00:03, 316264.65it/s]\n",
      " 21%|▊   | 268246/1306122 [00:00<00:03, 321338.80it/s]\n",
      " 23%|▉   | 303627/1306122 [00:00<00:03, 329762.43it/s]\n",
      " 26%|█   | 336436/1306122 [00:01<00:02, 328498.33it/s]\n",
      " 28%|█▏  | 370884/1306122 [00:01<00:02, 332466.05it/s]\n",
      " 29%|█▋    | 376737/1306122 [00:14<11:02, 1402.62it/s]\n",
      " 29%|█▋    | 376737/1306122 [00:14<11:02, 1402.62it/s]\n",
      " 31%|█▊    | 405073/1306122 [00:15<07:30, 1999.47it/s]\n",
      " 33%|█▉    | 432022/1306122 [00:15<05:06, 2847.26it/s]\n",
      " 35%|██    | 461210/1306122 [00:15<03:28, 4050.46it/s]\n",
      " 37%|██▏   | 486790/1306122 [00:15<02:22, 5747.09it/s]\n",
      " 40%|██▍   | 517722/1306122 [00:15<01:36, 8144.81it/s]\n",
      " 42%|██   | 544550/1306122 [00:15<01:06, 11484.91it/s]\n",
      " 44%|██▏  | 569550/1306122 [00:15<00:45, 16084.86it/s]\n",
      " 46%|██▎  | 602398/1306122 [00:15<00:31, 22502.65it/s]\n",
      " 49%|██▍  | 633690/1306122 [00:15<00:21, 31182.80it/s]\n",
      " 51%|██▌  | 666592/1306122 [00:15<00:14, 42803.32it/s]\n",
      " 53%|██▋  | 697482/1306122 [00:16<00:10, 57712.69it/s]\n",
      " 56%|██▊  | 736071/1306122 [00:16<00:07, 77446.46it/s]\n",
      " 59%|██▎ | 772892/1306122 [00:16<00:05, 101424.97it/s]\n",
      " 62%|██▍ | 809861/1306122 [00:16<00:03, 129550.82it/s]\n",
      " 65%|██▌ | 845751/1306122 [00:16<00:02, 160126.19it/s]\n",
      " 67%|██▋ | 880703/1306122 [00:16<00:02, 190980.92it/s]\n",
      " 70%|██▊ | 918610/1306122 [00:16<00:01, 224090.51it/s]\n",
      " 73%|██▉ | 956306/1306122 [00:16<00:01, 254750.82it/s]\n",
      " 76%|███ | 992510/1306122 [00:16<00:01, 275633.53it/s]\n",
      " 79%|██▎| 1030892/1306122 [00:17<00:00, 299852.39it/s]\n",
      " 82%|██▍| 1068546/1306122 [00:17<00:00, 318799.35it/s]\n",
      " 85%|██▌| 1105113/1306122 [00:17<00:00, 325572.08it/s]\n",
      " 87%|██▌| 1140987/1306122 [00:17<00:00, 324266.87it/s]\n",
      " 90%|██▋| 1176971/1306122 [00:17<00:00, 334056.67it/s]\n",
      " 93%|██▊| 1213478/1306122 [00:17<00:00, 342554.21it/s]\n",
      " 96%|██▊| 1248977/1306122 [00:17<00:00, 343088.68it/s]\n",
      " 99%|██▉| 1287269/1306122 [00:17<00:00, 353169.13it/s]\n",
      "100%|████| 1306122/1306122 [00:17<00:00, 73469.50it/s]\n",
      "  0%|                     | 0/1306122 [00:00<?, ?it/s]\n",
      "  1%|       | 9014/1306122 [00:00<00:14, 89484.26it/s]\n",
      "  3%|▏    | 37631/1306122 [00:00<00:11, 112632.78it/s]\n",
      "  5%|▎    | 65334/1306122 [00:00<00:09, 136878.90it/s]\n",
      "  7%|▎    | 94288/1306122 [00:00<00:07, 162398.72it/s]\n",
      "  9%|▎   | 121752/1306122 [00:00<00:06, 184818.65it/s]\n",
      " 11%|▍   | 149610/1306122 [00:00<00:05, 205243.45it/s]\n",
      " 13%|▌   | 175531/1306122 [00:00<00:05, 218512.62it/s]\n",
      " 16%|▌   | 203885/1306122 [00:00<00:04, 234462.67it/s]\n",
      " 18%|▋   | 230317/1306122 [00:00<00:04, 242221.55it/s]\n",
      " 20%|▊   | 256091/1306122 [00:01<00:04, 246144.19it/s]\n",
      " 22%|▊   | 281741/1306122 [00:01<00:04, 248496.20it/s]\n",
      " 24%|▉   | 307426/1306122 [00:01<00:03, 250429.41it/s]\n",
      " 26%|█   | 334872/1306122 [00:01<00:03, 257010.57it/s]\n",
      " 28%|█   | 361756/1306122 [00:01<00:03, 259899.24it/s]\n",
      " 30%|█▏  | 390010/1306122 [00:01<00:03, 265737.38it/s]\n",
      " 32%|█▎  | 418433/1306122 [00:01<00:03, 270476.52it/s]\n",
      " 34%|█▎  | 446407/1306122 [00:01<00:03, 272607.33it/s]\n",
      " 36%|█▍  | 475012/1306122 [00:01<00:03, 275921.51it/s]\n",
      " 39%|█▌  | 503859/1306122 [00:01<00:02, 278977.46it/s]\n",
      " 41%|█▋  | 531838/1306122 [00:02<00:02, 268969.65it/s]\n",
      " 43%|█▋  | 558869/1306122 [00:02<00:02, 268804.84it/s]\n",
      " 45%|█▊  | 586881/1306122 [00:02<00:02, 271487.01it/s]\n",
      " 47%|█▉  | 614478/1306122 [00:02<00:02, 272255.08it/s]\n",
      " 49%|█▉  | 644078/1306122 [00:02<00:02, 278369.78it/s]\n",
      " 51%|██  | 671985/1306122 [00:02<00:02, 277131.92it/s]\n",
      " 54%|██▏ | 701364/1306122 [00:02<00:02, 281339.06it/s]\n",
      " 56%|██▏ | 729549/1306122 [00:02<00:02, 275099.92it/s]\n",
      " 58%|██▎ | 757850/1306122 [00:02<00:01, 276865.77it/s]\n",
      " 60%|██▍ | 785586/1306122 [00:02<00:01, 276405.58it/s]\n",
      " 62%|██▍ | 813261/1306122 [00:03<00:01, 264825.91it/s]\n",
      " 64%|██▌ | 840550/1306122 [00:03<00:01, 266614.22it/s]\n",
      " 66%|██▋ | 868417/1306122 [00:03<00:01, 269553.43it/s]\n",
      " 69%|██▋ | 897360/1306122 [00:03<00:01, 274666.34it/s]\n",
      " 71%|██▊ | 925014/1306122 [00:03<00:01, 275032.21it/s]\n",
      " 73%|██▉ | 954231/1306122 [00:03<00:01, 279370.55it/s]\n",
      " 75%|███ | 983186/1306122 [00:03<00:01, 281655.84it/s]\n",
      " 77%|██▎| 1011394/1306122 [00:03<00:01, 276201.48it/s]\n",
      " 80%|██▍| 1039067/1306122 [00:03<00:00, 270934.72it/s]\n",
      " 82%|██▍| 1067708/1306122 [00:03<00:00, 274760.56it/s]\n",
      " 84%|██▌| 1095239/1306122 [00:04<00:00, 271084.52it/s]\n",
      " 86%|██▌| 1123082/1306122 [00:04<00:00, 272666.14it/s]\n",
      " 88%|██▋| 1150386/1306122 [00:04<00:00, 265063.00it/s]\n",
      " 90%|██▋| 1179019/1306122 [00:04<00:00, 270571.96it/s]\n",
      " 92%|██▊| 1207102/1306122 [00:04<00:00, 272984.63it/s]\n",
      " 95%|██▊| 1234499/1306122 [00:04<00:00, 272685.23it/s]\n",
      " 97%|██▉| 1263786/1306122 [00:04<00:00, 277863.66it/s]\n",
      " 99%|██▉| 1291626/1306122 [00:04<00:00, 274958.03it/s]\n",
      "100%|███| 1306122/1306122 [00:04<00:00, 269247.95it/s]"
     ]
    }
   ],
   "source": [
    "train[\"question_text\"] = train[\"question_text\"].progress_apply(lambda x: replace_typical_misspell(x))\n",
    "sentences = train[\"question_text\"].progress_apply(lambda x: x.split())\n",
    "to_remove = ['a','to','of','and']\n",
    "sentences = [[word for word in sentence if not word in to_remove] for sentence in tqdm(sentences)]\n",
    "vocab = build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                      | 0/242935 [00:00<?, ?it/s]\n",
      "  0%|          | 160/242935 [00:00<02:32, 1588.38it/s]\n",
      "  0%|          | 548/242935 [00:00<02:05, 1928.33it/s]\n",
      "  1%|         | 1552/242935 [00:00<01:34, 2543.84it/s]\n",
      "  2%|▏        | 4969/242935 [00:00<01:07, 3520.90it/s]\n",
      "  4%|▎        | 9448/242935 [00:00<00:47, 4864.76it/s]\n",
      "  6%|▍       | 15121/242935 [00:00<00:33, 6701.57it/s]\n",
      "  9%|▊       | 22964/242935 [00:00<00:23, 9233.08it/s]\n",
      " 14%|▉      | 34243/242935 [00:00<00:16, 12739.90it/s]\n",
      " 20%|█▍     | 48984/242935 [00:00<00:11, 17545.09it/s]\n",
      " 27%|█▊     | 64970/242935 [00:01<00:07, 23930.84it/s]\n",
      " 34%|██▎    | 82019/242935 [00:01<00:04, 32242.48it/s]\n",
      " 42%|██▍   | 100951/242935 [00:01<00:03, 42906.98it/s]\n",
      " 50%|██▉   | 120275/242935 [00:01<00:02, 55932.64it/s]\n",
      " 59%|███▌  | 143094/242935 [00:01<00:01, 72259.87it/s]\n",
      " 66%|███▉  | 161090/242935 [00:01<00:01, 80879.94it/s]\n",
      " 76%|███▊ | 184088/242935 [00:01<00:00, 100312.85it/s]\n",
      " 83%|████▏| 202109/242935 [00:01<00:00, 104330.03it/s]\n",
      " 93%|████▋| 225743/242935 [00:01<00:00, 125188.00it/s]\n",
      "100%|█████| 242935/242935 [00:02<00:00, 121215.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 60.43% of vocab\n",
      "Found embeddings for 98.96% of all text\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab, embedding_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bitcoin', 987),\n",
       " ('Quorans', 858),\n",
       " ('cryptocurrency', 822),\n",
       " ('Snapchat', 807),\n",
       " ('btech', 632),\n",
       " ('Brexit', 493),\n",
       " ('cryptocurrencies', 481),\n",
       " ('blockchain', 474),\n",
       " ('behaviour', 468),\n",
       " ('upvotes', 432),\n",
       " ('programme', 402),\n",
       " ('Redmi', 379),\n",
       " ('realise', 371),\n",
       " ('defence', 364),\n",
       " ('KVPY', 349),\n",
       " ('Paytm', 334),\n",
       " ('grey', 299),\n",
       " ('mtech', 281),\n",
       " ('Btech', 262),\n",
       " ('bitcoins', 254)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#我们发现，尽管我们改进了所有文本的嵌入量，从89%提高到99%。让我们再检查一遍oov单词\n",
    "oov[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#看起来不错。没有明显的oov词，我们可以快速修复。谢谢你的阅读和快乐的kaggling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('process_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('vocab.pkl', 'wb') as f:\n",
    "    pickle.dump(vocab, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# def load_obj(name ):\n",
    "#     with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "#         return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('vocab.txt','w', encoding='utf-8')\n",
    "f.write(str(vocab))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
